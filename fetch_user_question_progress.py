import requests
import json
import sys
import os
import argparse
from typing import List, Dict

def fetch_user_question_progress(app_id: str, limit: int = 1000, offset: int = 0) -> List[Dict]:
    """
    L·∫•y d·ªØ li·ªáu user question progress t·ª´ API
    
    Args:
        app_id: ID c·ªßa app
        limit: S·ªë l∆∞·ª£ng b·∫£n ghi m·ªói l·∫ßn (t·ªëi ƒëa c√≥ th·ªÉ l√† 1000)
        offset: V·ªã tr√≠ b·∫Øt ƒë·∫ßu
        
    Returns:
        Danh s√°ch c√°c b·∫£n ghi
    """
    url = "https://test-api-cms-v2-dot-micro-enigma-235001.uc.r.appspot.com/api/tools/get-user-question-progress-by-app-id"
    params = {
        "appId": app_id,
        "limit": limit,
        "offset": offset
    }
    
    try:
        response = requests.get(url, params=params, timeout=60)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"L·ªói khi g·ªçi API: {e}")
        return []

def fetch_all_data(app_id: str, total_limit: int = 100000) -> List[Dict]:
    """
    L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu v·ªõi pagination
    
    Args:
        app_id: ID c·ªßa app
        total_limit: T·ªïng s·ªë b·∫£n ghi mu·ªën l·∫•y
        
    Returns:
        Danh s√°ch t·∫•t c·∫£ c√°c b·∫£n ghi
    """
    all_data = []
    offset = 0
    batch_size = 1000  # L·∫•y 1000 b·∫£n ghi m·ªói l·∫ßn
    
    print(f"B·∫Øt ƒë·∫ßu l·∫•y d·ªØ li·ªáu (t·ªëi ƒëa {total_limit} b·∫£n ghi)...")
    
    while len(all_data) < total_limit:
        remaining = total_limit - len(all_data)
        current_limit = min(batch_size, remaining)
        
        print(f"ƒêang l·∫•y b·∫£n ghi {offset + 1} ƒë·∫øn {offset + current_limit}...")
        
        batch_data = fetch_user_question_progress(app_id, limit=current_limit, offset=offset)
        
        if not batch_data:
            print("Kh√¥ng c√≤n d·ªØ li·ªáu ho·∫∑c c√≥ l·ªói x·∫£y ra.")
            break
            
        all_data.extend(batch_data)
        print(f"ƒê√£ l·∫•y ƒë∆∞·ª£c {len(all_data)} b·∫£n ghi")
        
        # N·∫øu s·ªë b·∫£n ghi tr·∫£ v·ªÅ √≠t h∆°n limit, c√≥ th·ªÉ ƒë√£ h·∫øt d·ªØ li·ªáu
        if len(batch_data) < current_limit:
            print("ƒê√£ l·∫•y h·∫øt d·ªØ li·ªáu c√≥ s·∫µn.")
            break
            
        offset += len(batch_data)
        
        # N·∫øu ƒë√£ ƒë·ªß s·ªë l∆∞·ª£ng y√™u c·∫ßu, d·ª´ng l·∫°i
        if len(all_data) >= total_limit:
            break
    
    return all_data[:total_limit]  # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° total_limit

def main():
    parser = argparse.ArgumentParser(description='L·∫•y d·ªØ li·ªáu user question progress t·ª´ API')
    parser.add_argument('--app-id', type=str, default='5074526257807360', 
                        help='ID c·ªßa app (m·∫∑c ƒë·ªãnh: 5074526257807360)')
    parser.add_argument('--limit', type=int, default=100000, 
                        help='T·ªïng s·ªë b·∫£n ghi mu·ªën l·∫•y (m·∫∑c ƒë·ªãnh: 100000)')
    parser.add_argument('--output', type=str, default=None,
                        help='T√™n file output (m·∫∑c ƒë·ªãnh: user_question_progress_{limit}.json)')
    
    args = parser.parse_args()
    
    app_id = args.app_id
    total_records = args.limit
    
    # L·∫•y t·∫•t c·∫£ d·ªØ li·ªáu
    all_data = fetch_all_data(app_id, total_limit=total_records)
    
    # T·∫°o t√™n file output
    if args.output:
        output_file = args.output
    else:
        output_file = f"user_question_progress_{total_records}.json"
    
    print(f"\nƒêang l∆∞u {len(all_data)} b·∫£n ghi v√†o file {output_file}...")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ ƒê√£ l∆∞u th√†nh c√¥ng {len(all_data)} b·∫£n ghi v√†o file {output_file}")
    
    # T√≠nh k√≠ch th∆∞·ªõc file
    file_size = os.path.getsize(output_file) / (1024*1024)
    print(f"üìä K√≠ch th∆∞·ªõc file: {file_size:.2f} MB")

if __name__ == "__main__":
    main()

